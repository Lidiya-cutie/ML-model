{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в ансамбли: бэггинг. Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ансамблевые модели или просто ансамбли (ensembles) — это метод машинного обучения, где несколько простых моделей (часто называемых «слабыми учениками») обучаются для решения одной и той же задачи и объединяются для получения лучших результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимость использования ансамблей может возникнуть тогда, когда вы уже нашли хорошую модель и никак больше не можете повысить её качество. В этом случае можно перейти к более продвинутому методу: использовать не одну модель (пусть и очень хорошую), а ансамбли моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Говоря простыми словами, *ансамбли* — это объединение простых моделей в одного гиганта. Но объединять модели можно как угодно: например, взять тысячу разных логистических регрессий, а затем на их предсказаниях построить дерево решений, линейную регрессию или вообще нейронную сеть. А можно обучить сотню деревьев решений — построить целый лес, а для предсказания взять среднее. Вариаций объединения может быть сколько угодно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует три проверенных способа построения ансамблей:\n",
    "\n",
    "* **Бэггинг** — параллельно обучаем множество одинаковых моделей, а для предсказания берём среднее по предсказаниям каждой из моделей.\n",
    "* **Бустинг** — последовательно обучаем множество одинаковых моделей, где каждая новая модель концентрируется на тех примерах, где предыдущая допустила ошибку.\n",
    "* **Стекинг** — параллельно обучаем множество разных моделей, отправляем их результаты в финальную модель, и уже она принимает решение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> БЭГГИНГ. ОСНОВНЫЕ ИДЕИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Бэггинг (bagging)** — это алгоритм построения ансамбля путём параллельного обучения множества независимых друг от друга моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В основе алгоритма лежит статистический метод, который называется **бутстрэпом (bootstrap)**. Идея бутстрэпа заключается в генерации $k$ выборок размера $n$ (бутстрэп-выборок) из исходного набора данных размера $m$ путём случайного выбора элементов с повторениями в каждом из наблюдений. \n",
    "\n",
    "Схематично работу метода можно представить следующим образом:\n",
    "\n",
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/f9a7e335be61cede1d556e9f28768395/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/ML_3_7_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы взяли исходный набор данных размером $m=12$ наблюдений и сгенерировали $k=3$ бутстрэп-выборки размером $n=8$ наблюдений. Обратите внимание, что наблюдения в выборках могут повторяться.\n",
    "\n",
    "В частном случае можно генерировать выборки того же размера, то есть $n=m$. Таким образом, мы из набора данных создаём $k$ датасетов из исходного того же размера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Примечание**. Такие бутстрэп-выборки часто используются для оценки различных статистических показателей (например, разброса или доверительного интервала). Если вычислять статистические оценки на нескольких независимых выборках, то мы можем оценить их разброс. Поиск большого количества независимых выборок сложен в силу того, что для этого требуется слишком много данных. Поэтому мы используем бутстрэп, чтобы создать несколько выборок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обучим $k$ одинаковых моделей на каждой из сгенерированных выборок, сделаем предсказания, а затем усредним их. Так мы получим бэггинг.\n",
    "\n",
    "Схематично такой подход можно описать следующим образом:\n",
    "\n",
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/fac995faed28a74a308d254968e85514/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/ML_3_7_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Примечание**. В случае классификации «усреднение» означает мажоритарное голосование (принцип большинства голосов). То есть объект относится к тому классу, за который проголосовало большинство алгоритмов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно отметить, что в бэггинге в голосовании принимает участие модель одного вида. Эта модель называется **базовой моделью (base model)**. Нельзя обучить на половине сгенерированных наборов данных логистические регрессии, а на второй половине — деревья решений.\n",
    "\n",
    "* Смещение (bias) бэггинг-ансамбля не больше () смещения одного алгоритма из этого ансамбля.\n",
    "* Однако разброс (variance) бэггинг-ансамбля в  раз меньше, чем разброс одного алгоритма из ансамбля, где  — количество алгоритмов в ансамбле."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>  СЛУЧАЙНЫЙ ЛЕС"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Случайный лес (Random Forest)** — это самая распространённая реализация бэггинга, основанная на использовании в качестве базовой модели дерева решений. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо бутстрэпа, случайный лес использует [метод случайных подпространств](https://en.wikipedia.org/wiki/Random_subspace_method). Суть этого метода заключается в том, что каждая модель обучается не на всех признаках, а только на части из них. Такой подход позволяет уменьшить коррелированность между ответами деревьев и сделать их независимыми друг от друга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### АЛГОРИТМ ПОСТРОЕНИЯ СЛУЧАЙНОГО ЛЕСА ДЛЯ ЗАДАЧИ КЛАССИФИКАЦИИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть количество объектов в наборе данных равно N, а количество признаков — M. То есть размер набора данных — (N, M). Количество деревьев в лесу равно K. Тогда для обучения случайного леса необходимо выполнить следующие шаги:\n",
    "\n",
    "1. С помощью бутстрэпа создать K наборов данных размера (N, M).\n",
    "2. Для каждого сгенерированного набора данных применить метод случайных подпространств: выбрать L < M случайных признаков и получить K новых наборов данных размером (N, L).\n",
    "3. На каждом наборе данных обучить K деревьев решений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда поступят новые данные, нам нужно будет прогнать их через каждое дерево и объединить результаты отдельных деревьев мажоритарным голосованием или путём комбинирования вероятностей.\n",
    "\n",
    "Ниже приведена схема работы описанного алгоритма для решения задачи классификации. Для простоты лес состоит из четырёх деревьев (K=4).\n",
    "\n",
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/20c5cecc250686cec7b857a628caf6d8/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/ML_3_7_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, как работает алгоритм случайного леса, на примере: \n",
    "\n",
    "Пусть у нас есть набор данных со следующими факторами:\n",
    "\n",
    "* — возраст,\n",
    "* — доход в тысячах рублей,\n",
    "* — группа крови.\n",
    "**Целевой признак** ($y$) — подвергался ли человек операции хотя бы раз в жизни (1 — да, 0 — нет).\n",
    "\n",
    "Тогда, если мы обучим алгоритм случайного леса на представленных данных, мы получим следующую картину:\n",
    "\n",
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/da579d5f8abbca794aa3c0b097267209/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/ML_3_7_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество объектов в наборе данных N=5, а количество факторов — M=3 (+1 целевой признак, его мы не включаем в размерность). Таким образом, размер таблицы наблюдений — (5, 3). Количество деревьев в лесу K=4.\n",
    "\n",
    "1. На первом этапе алгоритма мы формируем K=4 бутстрэп выборки размером (5, 3), выбирая из таблицы строки случайным образом с возможностью повторения.\n",
    "2. На втором этапе мы случайным образом выбираем L=2 признаков из каждой таблицы и получаем четыре выборки размером (5, 2).\n",
    "3. На третьем этапе мы обучаем K=4 деревьев решений, каждое на своей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Обратите внимание, что деревья, из которых состоит лес, могут быть различной глубины и структуры в зависимости от того, насколько просто была разделима поданная выборка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда поступят новые данные, нам останется только подать их на вход каждого из деревьев, получить предсказания, а затем усреднить их путём мажоритарного голосования и получить ответ:\n",
    "\n",
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/eda5e5e86807409bb6d4bd25ba3ccf8c/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/ML_3_7_5.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
