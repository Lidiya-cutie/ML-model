{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mетрики регрессии. Недостатки аналитического решения"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценивают качество модели с помощью одного или нескольких показателей. Такой показатель в машинном обучении называется **метрикой**. И для каждого класса задач машинного обучения существуют свои метрики.\n",
    "\n",
    "**Метрика** - это численное выражеение качества моделирования."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## МЕТРИКИ РЕГРЕССИИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #\n",
    "import pandas as pd # \n",
    "import matplotlib.pyplot as plt # \n",
    "import seaborn as sns #\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [24.0, 21.6, 34.7, 33.4, 36.2]\n",
      "y^ = [29.82, 25.87, 30.73, 31.76, 29.49]\n"
     ]
    }
   ],
   "source": [
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', \n",
    "                'NOX', 'RM', 'AGE', 'DIS', 'RAD', \n",
    "                'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "boston = pd.read_csv('https://lms-cdn.skillfactory.ru/assets/courseware/v1/d4accdce7a25600298819f8e28e8d593/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/housing.csv',\n",
    "                     header=None, delimiter=r'\\s+', names=column_names)\n",
    "boston.head(3)\n",
    "X = boston[['LSTAT']] # матрица наблюдений\n",
    "y = boston['MEDV'] # вектор правильных ответов\n",
    "X.head()\n",
    "# y.head()\n",
    "# Создаем объект класа LinearRegression\n",
    "lr_lstat = linear_model.LinearRegression()\n",
    "# Обучаем модел - ищем параметры по МНК\n",
    "lr_lstat.fit(X, y)\n",
    "\n",
    "print(f'y = {list(y.head())}')\n",
    "print(f'y^ = {list(lr_lstat.predict(boston[[\"LSTAT\"]])[:5].round(2))}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмём первые пять наблюдений из нашей таблицы и предсказанные для них моделью lr_lstat ответы:\n",
    "\n",
    "$y = (24.0, 21.6, 34.7, 33.4, 36.2)$\n",
    "\n",
    "$\\hat y = (29.82, 25.87, 30.73, 31.76, 29.49)$\n",
    "\n",
    "На этих значениях будем рассматривать следующие метрики:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> ##### 1 - Средняя абсолютная ошибка — MAE (Mean Absolute Error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы посчитать данную метрику, нужно найти все остатки (разницы между предсказанным значением и реальным), взять от каждого из них модуль, сложить их и поделить на количество. Иными словами, нам нужно найти среднее арифметическое модуля отклонения предсказанного значения от реального.\n",
    "\n",
    "$MAE = {{\\Sigma^n_{i=1}|y_i - \\hat y_i|}\\over n}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная метрика интерпретируется очень легко: это число показывает, насколько в среднем наша модель ошибается. Чем меньше значение метрики, тем лучше."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MAE = {{|24.0 - 29.82| + |21.6 - 25.87| + |34.7 - 30.73| + |33.4- 31.76| + |36.2 - 29.49|}\\over 5} = 4.482$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть для нашего примера из пяти наблюдений в среднем модель ошибается на 4.482 тысячи долларов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Много ли это? Хороший вопрос, на который без эксперта-оценщика недвижимости будет сложно дать ответ. Однако можно попробовать посчитать ошибку в процентах, ведь в процентах всё воспринимается легче, и для этого нам пригодится следующая метрика — MAPE."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> ##### 2 - Средняя абсолютная ошибка в процентах — MAPE (Mean Absolute Percent Error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для её вычисления мы делим модуль разницы между предсказанием алгоритма и истинным значением на истинное значение. Затем складываем все результаты (для каждого объекта), делим на количество и умножаем на 100 %.\n",
    "\n",
    "$MAPE = \\sum \\limits_{i=1}^{n}{{|y_i - \\hat y_i|}\\over |y_i|}{100\\% \\over n}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта метрика показывает, на сколько процентов в среднем наше предсказание отклоняется от реального значения. Эта метрика отлично показывает себя в задачах, когда неизвестно, какое значение целевого показателя считать приемлемым."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, средняя ошибка — 2 тысячи долларов. Это много или мало? Смотря для чего... А вот средняя ошибка, равная 80 % — это много или мало? Определённо много.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MAPE = ({{|24.0 - 29.82|}\\over|24.0|} + {{|21.6 - 25.87|}\\over|21.6|} + {{|34.7 - 30.73|}\\over|34.7|} + {{|33.4- 31.76|}\\over|33.4|} +{{|36.2 - 29.49|}\\over|36.2|}){100\\% \\over 5} = 15.781\\%$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, на первых пяти наблюдениях модель в среднем ошибается на 15.781 %. Это довольно неплохой результат."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> ##### 3 - Средняя квадратическая ошибка — MSE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный показатель мы используем в линейной регрессии в качестве функции потерь, но ничто не мешает нам также использовать его и в качестве метрики.\n",
    "\n",
    "$MSE = {\\Sigma^n_{i=1}{{(y_i - \\hat y_i)^2}}\\over{n}}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная метрика хуже поддаётся интерпретации, чем предыдущая, так как измеряется не в единицах, а в квадратах единиц. Она чаще используется для внутреннего обсуждения между дата-сайентистами, заказчику такая метрика может быть непонятна."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MSE = {{(24.0 - 29.82)^2 + (21.6 - 25.87)^2 + (34.7 - 30.73)^2 + (33.4- 31.76)^2 + (36.2 - 29.49)^2}\\over 5} = 22.116[(тыс.\\$)^2]$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, для нашего примера квадрат отклонения составляет 22.116 тысяч долларов в квадрате.\n",
    "\n",
    "Согласитесь, не очень понятно, о чём идет речь. Однако данная метрика является популярной, так как позволяет «штрафовать» модель за очень большие ошибки."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что значит «штрафовать»?**\n",
    "\n",
    "Например, расхождение в 200 единиц в метрике MSE воспринимается как $200^2$, а в метрике MAE это расхождение воспринимается как 200. Поэтому, если у нас есть две модели, но одна из них допускает большие ошибки, эти ошибки становятся ещё больше при расчёте метрики MSE, и нам легче сравнить модели между собой."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но в то же время это и проклятие MSE. Если в данных присутствуют выбросы, метрика может быть необъективной. Если модель будет утверждать, что цена здания — 30 тысяч долларов, а в наборе данных ему соответствует цена в 3 миллиона долларов, то при возведении такой ошибки в квадрат получится 9 миллионов, что может сбить с толку исследователя. Необходимо скептически относиться к данной метрике, если вы не проводили исследование данных на предмет наличия выбросов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> ##### 4 - Корень из средней квадратической ошибки — RMSE (Root Mean Squared Error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для получения RMSE надо просто извлечь квадратный корень из MSE:\n",
    "\n",
    "$RMSE = \\sqrt{MSE} = \\sqrt{{\\Sigma^n_{i=1}{{(y_i - \\hat y_i)^2}}\\over{n}}}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корень извлекается для того, чтобы привести размерности ответов и ошибок в соответствие и сделать метрику более понятной.\n",
    "\n",
    "$RMSE = \\sqrt{22.116} = 4.702[тыс.\\$]$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преимущества и недостатки этой метрики такие же, как и у MSE, к преимуществам добавляется только понятная размерность."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> ##### 5 - Коэффициент детерминации ($R^2$)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все рассматриваемые ранее метрики имели масштаб от 0 до $+\\infty$. Чем это плохо?\n",
    "\n",
    "А что если нам скажут, что MSE для модели составляет 32? Должны ли мы улучшить модель, или она достаточно хороша? А что если MSE = 0.4?\n",
    "\n",
    "На самом деле, трудно понять, хороша модель или нет, не сравнив её показатели с теми же показателями других моделей."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициент детерминации, или $R^2$, является ещё одним показателем, который мы можем использовать для оценки модели. Он тесно связан с MSE, но его преимущество в том, что $R^2$ всегда находится в промежутке между $-\\infty$ и 1.\n",
    "\n",
    "$R^2 = {1 - {MSE\\over MSE_{mean}}},$\n",
    "\n",
    "где\n",
    "\n",
    "$MSE_{mean} = {\\Sigma^n_{i=1}{{(y_i - \\overline y)^2}}\\over{n}},$\n",
    "\n",
    "где $\\overline y - $ среднее по вектору правильных ответов. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть $R^2$ показывает, насколько наша модель лучше, чем если бы все предсказания были средним по правильным ответам."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как считается $R^2$. Сначала рассчитаем среднее по правильным ответам:\n",
    "\n",
    "$\\overline y = {{24.0 + 21.6 + 34.7 + 33.4 + 36.2}\\over 5} = 29,98$\n",
    "\n",
    "Теперь рассчитаем $MSE_{mean}:$\n",
    "\n",
    "$MSE_{mean} = {{(24.0 - 29.98)^2 + (21.6 - 29.98)^2 + (34.7 - 29.98)^2 + (33.4- 29.98)^2 + (36.2 - 29.98)^2}\\over 5} = 35.72$\n",
    "\n",
    "И, наконец, сам $R^2$:\n",
    "\n",
    "$R^2 = {1 - {22.116\\over 35.72}} = 0.38$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ещё одна интерпретация данной метрики. Статистически показатель  описывает, какую долю информации о зависимости (дисперсии) смогла уловить модель."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удовлетворительным $R^2$ считается показатель выше 0.5: чем ближе к 1, тем лучше. Отрицательные значения $R^2$ говорят о том, что построенная модель настолько плоха, что лучше было бы присвоить всем ответам среднее значение."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обобщим всё вышесказанное в виде таблицы:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## РАСЧЁТ МЕТРИК НА PYTHON"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настало время проверить качество построенных нами ранее моделей линейной регрессии: *lr_lstat* и *lr_full*.\n",
    "\n",
    "Весь набор функций для вычисления метрик в sklearn находится в модуле [metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics). Давайте его импортируем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции, которые нам понадобятся:\n",
    "\n",
    "* *mean_absolute_error()* — расчёт MAE;\n",
    "* *mean_squared_error()* — расчёт MSE;\n",
    "* *mean_absolute_percentage_error()* — расчёт MAPE;\n",
    "* *r2_score()* — расчёт коэффициента детерминации $R^2$.\n",
    "\n",
    "В каждую из функций достаточно передать правильные ответы и предсказания, и функция вернёт рассчитанную метрику."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для расчёта метрики RMSE нет специальной функции, однако мы знаем, что для её расчёта достаточно извлечь квадратный корень из MSE.\n",
    "\n",
    "Из-за особенностей реализации функция *mean_absolute_percentage_error()* возвращает результат не в процентах, а в долях. Чтобы отобразить результат в процентах, необходимо умножить его на 100."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте вычислим метрики и выведем их на экран, округлив до третьего знака после запятой. Начнём с модели *lr_lstat*: сделаем предсказание на основании признака *LSTAT* и передадим истинные и предсказанные медианные цены в функции для расчёта метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE score: 4.505 thou.$\n",
      "RMSE score: 6.203 thou.$\n",
      "MAPE score: 21.352 thou.%\n",
      "R2 score: 0.544\n"
     ]
    }
   ],
   "source": [
    "# Делаем предсказание по признаку LSTAT\n",
    "y_predict_lstat = lr_lstat.predict(boston[['LSTAT']])\n",
    "# Рассчитываем MAE\n",
    "print(f'MAE score: {metrics.mean_absolute_error(y, y_predict_lstat):.3f} thou.$')\n",
    "# Рассчитываем RMSE\n",
    "print(f'RMSE score: {(np.sqrt(metrics.mean_squared_error(y, y_predict_lstat))):.3f} thou.$')\n",
    "# Рассчитываем MAPE\n",
    "print(f'MAPE score: {(metrics.mean_absolute_percentage_error(y, y_predict_lstat) * 100):.3f} thou.%')\n",
    "# Рассчитываем коэффициент детерминации\n",
    "print(f'R2 score: {metrics.r2_score(y, y_predict_lstat):.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проделываем ту же самую операцию для второй модели линейной регрессии, *lr_full*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE score: 3.271 thou.$\n",
      "RMSE score: 4.679 thou.$\n",
      "MAPE score: 16.417 %\n",
      "R2 score: 0.741\n"
     ]
    }
   ],
   "source": [
    "# Составляем список факторов(исключили целевой столбец)\n",
    "features = boston.drop('MEDV', axis=1).columns\n",
    "# Составляем матрицу наблюдений Х и вектор ответов у\n",
    "X = boston[features]\n",
    "y = boston['MEDV']\n",
    "# Создаем объект класса LinearRegression\n",
    "lr_full = linear_model.LinearRegression()\n",
    "# Обучаем модель - ищем параметры по МНК\n",
    "lr_full.fit(X, y)\n",
    "# Делаем предсказание по всем признакам\n",
    "y_predict_full = lr_full.predict(boston[features])\n",
    "# Рассчитываем MAE\n",
    "print(f'MAE score: {metrics.mean_absolute_error(y, y_predict_full):.3f} thou.$')\n",
    "# Рассчитываем RMSE\n",
    "print(f'RMSE score: {(np.sqrt(metrics.mean_squared_error(y, y_predict_full))):.3f} thou.$')\n",
    "# Рассчитываем MAPE\n",
    "print(f'MAPE score: {(metrics.mean_absolute_percentage_error(y, y_predict_full) * 100):.3f} %')\n",
    "# Рассчитываем коэффициент детерминации\n",
    "print(f'R2 score: {metrics.r2_score(y, y_predict_full):.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним полученные результаты:\n",
    "\n",
    "* $MAE$: в среднем первая модель ошибается на  4.505 тыс. долларов, а вторая — на 3.271 тыс. долларов.\n",
    "* $RMSE$: среднеквадратичное отклонение первой модели от истинных ответов составляет 6.203 тыс. долларов, а второй — 4.679.\n",
    "* $MAPE$: первая модель ошибается на 21.352 %, а вторая — на 16.417 %.\n",
    "* $R^2$: доля объясняемой информации (дисперсии), которую улавливает первая модель, — 0.544, а вторая — 0.741.\n",
    "\n",
    "Очевидно, что по всем метрикам вторая модель, построенная на основе всех признаков в данных, превосходит первую."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ Следует отметить, что для задач регрессии существует множество метрик, и мы рассмотрели только наиболее распространённые из них. Весь список метрик и их расчёт в *sklearn* вы можете найти [здесь](https://scikit-learn.ru/3-3-metrics-and-scoring-quantifying-the-quality-of-predictions/#regression-metrics)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, у нас есть истинные ответы y_true = [1.23, 2.35, 2.75] и предсказания модели y_pred = [1.01, 12.3, 2.74]. Посчитаем метрику RMSE, ответ округлим до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score: 5.75\n"
     ]
    }
   ],
   "source": [
    "y_true = [1.23, 2.35, 2.75]\n",
    "y_pred = [1.01, 12.3, 2.74]\n",
    "print(f'RMSE score: {(np.sqrt(metrics.mean_squared_error(y_true, y_pred))):.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чему равен коэффициент детерминации на следующих данных?\n",
    "Истинные ответы: y_true = [22.4, 20.6, 23.9, 22.0, 11.9]\n",
    "\n",
    "Предсказанные ответы: y_pred = [20.5, 20.2, 20.3, 19.0, 11.0]\n",
    "\n",
    "Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.71\n"
     ]
    }
   ],
   "source": [
    "y_true = [22.4, 20.6, 23.9, 22.0, 11.9]\n",
    "y_pred = [20.5, 20.2, 20.3, 19.0, 11.0]\n",
    "print(f'R2 score: {metrics.r2_score(y_true, y_pred):.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## НЕДОСТАТКИ АНАЛИТИЧЕСКОГО РЕШЕНИЯ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним модель линейной регрессии и формулу аналитического решения по методу наименьших квадратов:\n",
    "\n",
    "$\\overline{w} = {(X^TX)}^{-1}X^Ty = QX^Ty$\n",
    "\n",
    "Метод наименьших квадратов позволяет очень просто получить коэффициенты , подставив таблицу в формулу. Вот, собственно, и всё «обучение»."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует [теорема Гаусса-Маркова](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%93%D0%B0%D1%83%D1%81%D1%81%D0%B0_%E2%80%94_%D0%9C%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D0%B0), которая говорит о том, что, если выполнены все условия теоремы, МНК всегда находит оптимальные оценки параметров. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Казалось бы, относительно простая математика: надо всего лишь перемножить матрицы между собой и получить ответ. Особенно простой эта задача должна быть для компьютера. Но нам так кажется, поскольку мы ранее не сталкивались с матричным умножением и будем говорить о нём только в модулях по линейной алгебре."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Оказывается, у такого простого подхода есть один большой минус — это работа с большим количеством признаков.***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте внимательно посмотрим на операцию обращения матриц (возведение в степень -1):\n",
    "\n",
    "$Q = (X^TX)^{-1}$\n",
    "\n",
    "Таблица $X$ имеет размер $(n, m)$, то есть у неё $n$ строк и $m$ столбцов. Таблица $X^T$ — это результат транспонирования матриц (замены строк и столбцов местами), то есть её размерность — $(m, n)$. Забегая вперёд, отметим, что по правилам умножения матриц результат умножения будет иметь размерность $(n, m) \\times (n, m) = (m, m)$, где $m$ — это число столбцов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь представим, что у нас не 13 признаков, а 1300. То есть матрица  имеет размерность $(m, m) = (1300, 1300)$. Но мы делаем вычисления на компьютере, так ведь? Сложностей быть не должно, но... В модулях по линейной алгебре мы увидим, что обращение матриц — очень ресурсозатратная операция. У неё кубическая сложность, то есть если размер матрицы — $(m, m)$, то на её обращение понадобится $m^3$ операций. Для нашего примера это $1300^3 = 2197000000$!\n",
    "\n",
    "Обращение матриц больших размеров может стать очень трудоёмким процессом при работе с большими объёмами данных."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Второй недостаток МНК — это невозможность инкрементального обучения, или обучения в режиме реального времени.***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представьте, что мы построили модель, но собираемся её уточнять в процессе эксплуатации. К нам приходят всё новые данные, и мы должны изменять параметры модели, подстраиваясь под новые зависимости.\n",
    "\n",
    "Если мы используем метод fit() для модели LinearRegression и передадим в него новые данные, то коэффициенты модели будут рассчитаны по новым данным, а прошлые наблюдения будут забыты. То есть придётся добавлять данные в таблицу и переобучать модель на всех доступных данных ещё раз."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Первая и вторая проблемы решаются с помощью замены аналитического МНК на численные методы, такие как градиентный спуск.*\n",
    "\n",
    "*Третий недостаток МНК больше теоретический и заключается в том, что матрица $Q = (X^TX)^{-1}$ в результате вычислений может не существовать. Это связано с математическими особенностями вычисления обратной матрицы, которые мы рассмотрим далее в курсе.* \n",
    "\n",
    "*Причина этой проблемы — мультиколлинеарность факторов (сильная корреляционная связь). Из-за этого коэффициенты линейной регрессии становятся слишком большими и модель становится неустойчивой.* \n",
    "\n",
    "*Проблема решается с помощью регуляризации.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
